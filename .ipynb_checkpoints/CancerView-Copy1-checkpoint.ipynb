{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:33507/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/May/2017 15:01:06] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2017 15:01:22] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2017 15:02:12] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2017 15:02:25] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect\n",
    "from bokeh.embed import components\n",
    "import PubDatePlotting as pdp\n",
    "#import StateGraph as sg\n",
    "\n",
    "# output_notebook()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.vars = {}\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    # nquestions=app_lulu.nquestions\n",
    "    if request.method == 'GET':\n",
    "        return render_template('select_cancer.html')\n",
    "    else:\n",
    "        app.vars['cancertype'] = request.form['cancertype']\n",
    "\n",
    "        p1 = pdp.pubByDate(app.vars['cancertype'], False)\n",
    "        p2 = pdp.pubByDate(app.vars['cancertype'], True)\n",
    "        p3, p4 = stateGraph(app.vars['cancertype'])\n",
    "        plots = {'p1': p1, 'p2': p2, 'p3': p3, 'p4': p4}\n",
    "        script, div = components(plots)\n",
    "\n",
    "        return render_template('view_cancer.html', script=script, div=div, ctype=app.vars['cancertype'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=33507)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PubDatePlotting\n",
    "# reading in data from pickles and plotting data\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.embed import components\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "countFile = \"CancerPubsWordCounts\"\n",
    "dataDir = \"./static/\"\n",
    "years = [2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002, 2001, 2000, 1999,\n",
    "         1998]\n",
    "\n",
    "\n",
    "# for loading counts files from previous analysis, later convert to searching db for counts\n",
    "def loadCounts(cf):\n",
    "    # need to normalize to total pubs at some point, maybe normalize by total number of cancer pubs\n",
    "    lCounts = []\n",
    "    for year in years:\n",
    "        lCounts.append(pickle.load(open(dataDir + cf + str(year) + \".pkl\", \"rb\")))\n",
    "    return lCounts\n",
    "\n",
    "\n",
    "def pubByDate(ctype, norm):\n",
    "    lCounts = loadCounts(countFile)\n",
    "\n",
    "    ys = []\n",
    "\n",
    "    for counts in lCounts:\n",
    "        # number of counts per cancer / sum to normalize for fraction of total publication\n",
    "        if (norm):\n",
    "            ys.append(counts[ctype.lower()] / sum(counts.values()))\n",
    "            ftit = ctype + \" cancer pubs / total cancer pubs\"\n",
    "            ylab = \"Publications (normalized)\"\n",
    "        else:\n",
    "            ys.append(counts[ctype.lower()])\n",
    "            ftit = ctype + \" cancer publications\"\n",
    "            ylab = \"Publications\"\n",
    "            # print(ctype)\n",
    "            # print(counts[ctype])\n",
    "\n",
    "    p = figure(title=ftit, plot_width=400, plot_height=400, x_axis_label=\"Year\", y_axis_label=ylab)\n",
    "\n",
    "    # to add legend use: legend=ctype\n",
    "    p.line(years, ys, color='red')\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########ASYNCIO version of StateGraph\n",
    "\n",
    "# StateGraph -  used to pull data from pubmed through an api\n",
    "from aiohttp import ClientSession\n",
    "import asyncio\n",
    "#import concurrent.futures\n",
    "#import requests\n",
    "\n",
    "import json\n",
    "from bokeh.sampledata import us_states\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "import pickle\n",
    "\n",
    "dataDir = \"./static/\"\n",
    "moneyFile = \"FundingPerState2016.pkl\"\n",
    "\n",
    "# affiliation = AD\n",
    "searchField = \"[AD]\"\n",
    "us_states = us_states.data.copy()\n",
    "del us_states[\"HI\"]\n",
    "del us_states[\"AK\"]\n",
    "\n",
    "state_xs = [us_states[code][\"lons\"] for code in us_states]\n",
    "state_ys = [us_states[code][\"lats\"] for code in us_states]\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text()\n",
    "\n",
    "###add states correlating with responses############\n",
    "async def run(states, ss):\n",
    "    tasks = []\n",
    "\n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    async with ClientSession() as session:\n",
    "        for state in states:\n",
    "            tu = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=\"+ss+\"&mindate=2012/01/01&maxdate=2016/12/31&usehistory=y&retmode=json\"\n",
    "            task = asyncio.ensure_future(fetch(tu, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # you now have all response bodies in this variable\n",
    "        #responses can be converted to json, originally were strings\n",
    "        #print(json.loads(responses[0]))\n",
    "    return responses\n",
    "\n",
    "# gets data from each state while string : ss=searchstring\n",
    "def getStates(ss):\n",
    "    #start threads and create queue of URLs\n",
    "    loop = asyncio.get_event_loop()\n",
    "    states = [us_states[state][\"name\"] for state in us_states]\n",
    "    future = asyncio.ensure_future(run(states,ss))\n",
    "    res = loop.run_until_complete(future)\n",
    "    #print(res)\n",
    "    for idx, state in enumerate(us_states):\n",
    "        search_data = json.loads(res[idx])\n",
    "        #webenv = search_data[\"esearchresult\"]['webenv']\n",
    "        total_records = int(search_data[\"esearchresult\"]['count'])\n",
    "        us_states[state][\"count\"] = total_records\n",
    "        \n",
    "\n",
    "def stateGraph(ss):\n",
    "    p = figure(title=ss + \" Cancer Publications\",\n",
    "               toolbar_location=\"left\", plot_width=800, plot_height=510)\n",
    "    p2 = figure(title=ss + \" Cancer Publications (Normalized by funding)\",\n",
    "                toolbar_location=\"left\", plot_width=800, plot_height=510)\n",
    "    p.xaxis.visible = False\n",
    "    p.xgrid.visible = False\n",
    "    p.yaxis.visible = False\n",
    "    p.ygrid.visible = False\n",
    "    \n",
    "    p2.xaxis.visible = False\n",
    "    p2.xgrid.visible = False\n",
    "    p2.yaxis.visible = False\n",
    "    p2.ygrid.visible = False\n",
    "\n",
    "    ##FOR SEARCHING YOU WILL NEED TO ESCAPE SPACES AND SPECIAL CHARS\n",
    "    getStates(ss+\"+cancer\")\n",
    "\n",
    "    # unnormalized to money version\n",
    "    state_counts = [us_states[code][\"count\"] for code in us_states]\n",
    "    state_counts_norm = state_counts\n",
    "    max_state_counts = max(state_counts)\n",
    "    state_counts = [x / max_state_counts for x in state_counts]\n",
    "\n",
    "    # normalized to money\n",
    "    fbs = pickle.load(open(dataDir + moneyFile, \"rb\"))\n",
    "    state_counts_norm = [us_states[code][\"count\"] / fbs[us_states[code][\"name\"]] for code in us_states]\n",
    "    max_state_counts_norm = max(state_counts_norm)\n",
    "    state_counts_norm = [x / max_state_counts_norm for x in state_counts_norm]\n",
    "\n",
    "    p.patches(state_xs, state_ys, fill_color=\"#377BA8\", fill_alpha=state_counts,\n",
    "              line_color=\"#884444\", line_width=1.5)\n",
    "\n",
    "    p2.patches(state_xs, state_ys, fill_color=\"#377BA8\", fill_alpha=state_counts_norm,\n",
    "               line_color=\"#884444\", line_width=1.5)\n",
    "\n",
    "    #show(p)\n",
    "    #show(p2)\n",
    "    return p, p2\n",
    "\n",
    "#p, p2 = stateGraph(\"prostate\")\n",
    "#show(p)\n",
    "#show(p2)\n",
    "# stateGraph(\"lung\")\n",
    "# stateGraph(\"breast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast%20AND%20cancer%5BAffiliation%5D\n"
     ]
    }
   ],
   "source": [
    "#######URL Search Parsing\n",
    "\n",
    "from urllib.parse import quote\n",
    "\n",
    "def urlFix(s):\n",
    "    return urllib.parse.quote(s)\n",
    "\n",
    "#print(urlFix('breast AND cancer[Affiliation]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# StateGraph -  used to pull data from pubmed through an api\n",
    "import requests\n",
    "import json\n",
    "from bokeh.sampledata import us_states\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "import pickle\n",
    "\n",
    "dataDir = \"./static/\"\n",
    "moneyFile = \"FundingPerState2016.pkl\"\n",
    "\n",
    "# affiliation = AD\n",
    "searchField = \"[AD]\"\n",
    "us_states = us_states.data.copy()\n",
    "del us_states[\"HI\"]\n",
    "del us_states[\"AK\"]\n",
    "\n",
    "state_xs = [us_states[code][\"lons\"] for code in us_states]\n",
    "state_ys = [us_states[code][\"lats\"] for code in us_states]\n",
    "\n",
    "\n",
    "# gets data from each state while string : ss=searchstring\n",
    "def getStates(ss):\n",
    "    for state in us_states:\n",
    "        # print(state)\n",
    "        us_states[state][\"count\"] = getState(ss, us_states[state][\"name\"])\n",
    "\n",
    "\n",
    "def getState(ss, state):\n",
    "    search_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=\" + state + searchField + \"+AND+\" + ss + \"+AND+cancer&mindate=2012/01/01&maxdate=2016/12/31&usehistory=y&retmode=json\"\n",
    "    search_r = requests.post(search_url)\n",
    "    search_data = search_r.json()\n",
    "    webenv = search_data[\"esearchresult\"]['webenv']\n",
    "    total_records = int(search_data[\"esearchresult\"]['count'])\n",
    "    return total_records\n",
    "\n",
    "\n",
    "def stateGraph(ss):\n",
    "    p = figure(title=ss + \" Cancer Publications\",\n",
    "               toolbar_location=\"left\", plot_width=800, plot_height=510)\n",
    "    p2 = figure(title=ss + \" Cancer Publications (Normalized by NIH funding)\",\n",
    "                toolbar_location=\"left\", plot_width=800, plot_height=510)\n",
    "    p.xaxis.visible = False\n",
    "    p.xgrid.visible = False\n",
    "    p.yaxis.visible = False\n",
    "    p.ygrid.visible = False\n",
    "    \n",
    "    p2.xaxis.visible = False\n",
    "    p2.xgrid.visible = False\n",
    "    p2.yaxis.visible = False\n",
    "    p2.ygrid.visible = False\n",
    "\n",
    "    ##FOR SEARCHING YOU WILL NEED TO ESCAPE SPACES AND SPECIAL CHARS\n",
    "    getStates(ss)\n",
    "\n",
    "    # unnormalized to money version\n",
    "    state_counts = [us_states[code][\"count\"] for code in us_states]\n",
    "    state_counts_norm = state_counts\n",
    "    max_state_counts = max(state_counts)\n",
    "    state_counts = [x / max_state_counts for x in state_counts]\n",
    "\n",
    "    # normalized to money\n",
    "    fbs = pickle.load(open(dataDir + moneyFile, \"rb\"))\n",
    "    state_counts_norm = [us_states[code][\"count\"] / fbs[us_states[code][\"name\"]] for code in us_states]\n",
    "    max_state_counts_norm = max(state_counts_norm)\n",
    "    state_counts_norm = [x / max_state_counts_norm for x in state_counts_norm]\n",
    "\n",
    "    p.patches(state_xs, state_ys, fill_color=\"#377BA8\", fill_alpha=state_counts,\n",
    "              line_color=\"#884444\", line_width=1.5)\n",
    "\n",
    "    p2.patches(state_xs, state_ys, fill_color=\"#377BA8\", fill_alpha=state_counts_norm,\n",
    "               line_color=\"#884444\", line_width=1.5)\n",
    "\n",
    "    # show(p)\n",
    "    # show(p2)\n",
    "    return p, p2\n",
    "\n",
    "# stateGraph(\"prostate\")\n",
    "# stateGraph(\"lung\")\n",
    "# stateGraph(\"breast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########QUEUE WORKED IT JUST WASN'T working with Pubmed, couldn't handle parallel request\n",
    "\n",
    "# StateGraph -  used to pull data from pubmed through an api\n",
    "import requests\n",
    "import json\n",
    "from bokeh.sampledata import us_states\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "import pickle\n",
    "#from urlparse import urlparse\n",
    "from threading import Thread\n",
    "#import httplib, sys\n",
    "from queue import Queue\n",
    "\n",
    "dataDir = \"./static/\"\n",
    "moneyFile = \"FundingPerState2016.pkl\"\n",
    "\n",
    "# affiliation = AD\n",
    "searchField = \"[AD]\"\n",
    "us_states = us_states.data.copy()\n",
    "del us_states[\"HI\"]\n",
    "del us_states[\"AK\"]\n",
    "\n",
    "state_xs = [us_states[code][\"lons\"] for code in us_states]\n",
    "state_ys = [us_states[code][\"lats\"] for code in us_states]\n",
    "\n",
    "\n",
    "# gets data from each state while string : ss=searchstring\n",
    "def getStates(ss):\n",
    "    q = Queue(len(us_states))\n",
    "    \n",
    "    #start threads and create queue of URLs\n",
    "    for state in us_states:\n",
    "        surl = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=\" + state + searchField + \"+AND+\" + ss + \"+AND+cancer&mindate=2012/01/01&maxdate=2016/12/31&usehistory=y&retmode=json\"\n",
    "        q.put(surl)\n",
    "        t = Thread(target=getState, args=[state,q])\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "        \n",
    "        \n",
    "\n",
    "#worker function\n",
    "def getState(state,q):\n",
    "    url = q.get()\n",
    "    search_r = requests.post(url)\n",
    "    search_data = search_r.json()\n",
    "    webenv = search_data[\"esearchresult\"]['webenv']\n",
    "    total_records = int(search_data[\"esearchresult\"]['count'])\n",
    "    \n",
    "    us_states[state][\"count\"] = total_records\n",
    "    q.task_done()\n",
    "#     status, url = getStatus(url)\n",
    "#     doSomethingWithResult(status, url)\n",
    "#     q.task_done()\n",
    "\n",
    "\n",
    "def stateGraph(ss):\n",
    "    p = figure(title=ss + \" Cancer Publications\",\n",
    "               toolbar_location=\"left\", plot_width=800, plot_height=510)\n",
    "    p2 = figure(title=ss + \" Cancer Publications (Normalized by funding)\",\n",
    "                toolbar_location=\"left\", plot_width=800, plot_height=510)\n",
    "    p.xaxis.visible = False\n",
    "    p.xgrid.visible = False\n",
    "    p.yaxis.visible = False\n",
    "    p.ygrid.visible = False\n",
    "    \n",
    "    p2.xaxis.visible = False\n",
    "    p2.xgrid.visible = False\n",
    "    p2.yaxis.visible = False\n",
    "    p2.ygrid.visible = False\n",
    "\n",
    "    ##FOR SEARCHING YOU WILL NEED TO ESCAPE SPACES AND SPECIAL CHARS\n",
    "    getStates(ss)\n",
    "\n",
    "    # unnormalized to money version\n",
    "    state_counts = [us_states[code][\"count\"] for code in us_states]\n",
    "    state_counts_norm = state_counts\n",
    "    max_state_counts = max(state_counts)\n",
    "    state_counts = [x / max_state_counts for x in state_counts]\n",
    "\n",
    "    # normalized to money\n",
    "    fbs = pickle.load(open(dataDir + moneyFile, \"rb\"))\n",
    "    state_counts_norm = [us_states[code][\"count\"] / fbs[us_states[code][\"name\"]] for code in us_states]\n",
    "    max_state_counts_norm = max(state_counts_norm)\n",
    "    state_counts_norm = [x / max_state_counts_norm for x in state_counts_norm]\n",
    "\n",
    "    p.patches(state_xs, state_ys, fill_color=\"#377BA8\", fill_alpha=state_counts,\n",
    "              line_color=\"#884444\", line_width=1.5)\n",
    "\n",
    "    p2.patches(state_xs, state_ys, fill_color=\"#377BA8\", fill_alpha=state_counts_norm,\n",
    "               line_color=\"#884444\", line_width=1.5)\n",
    "\n",
    "    # show(p)\n",
    "    # show(p2)\n",
    "    return p, p2\n",
    "\n",
    "# stateGraph(\"prostate\")\n",
    "# stateGraph(\"lung\")\n",
    "# stateGraph(\"breast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###example from which the queue data was built for above\n",
    "\n",
    "from urlparse import urlparse\n",
    "from threading import Thread\n",
    "import httplib, sys\n",
    "from Queue import Queue\n",
    "\n",
    "concurrent = 200\n",
    "\n",
    "def doWork():\n",
    "    while True:\n",
    "        url = q.get()\n",
    "        status, url = getStatus(url)\n",
    "        doSomethingWithResult(status, url)\n",
    "        q.task_done()\n",
    "\n",
    "def getStatus(ourl):\n",
    "    try:\n",
    "        url = urlparse(ourl)\n",
    "        conn = httplib.HTTPConnection(url.netloc)   \n",
    "        conn.request(\"HEAD\", url.path)\n",
    "        res = conn.getresponse()\n",
    "        return res.status, ourl\n",
    "    except:\n",
    "        return \"error\", ourl\n",
    "\n",
    "def doSomethingWithResult(status, url):\n",
    "    print status, url\n",
    "\n",
    "q = Queue(concurrent * 2)\n",
    "for i in range(concurrent):\n",
    "    t = Thread(target=doWork)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "try:\n",
    "    for url in open('urllist.txt'):\n",
    "        q.put(url.strip())\n",
    "    q.join()\n",
    "except KeyboardInterrupt:\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District of Columbia\n",
      "{'Alabama': 294964217, 'Arizona': 163447535, 'Arkansas': 96652655, 'California': 3686026589, 'Colorado': 349974172, 'Connecticut': 510609681, 'Delaware': 45371848, 'District Of Columbia': 214175791, 'Florida': 531720813, 'Georgia': 520595434, 'Idaho': 14139675, 'Illinois': 818027921, 'Indiana': 225125822, 'Iowa': 170060863, 'Kansas': 91306154, 'Kentucky': 163613208, 'Louisiana': 141817492, 'Maine': 75619398, 'Maryland': 1465624060, 'Massachusetts': 2572549176, 'Michigan': 669562129, 'Minnesota': 520225717, 'Mississippi': 53538828, 'Missouri': 508984218, 'Montana': 37310308, 'Nebraska': 107024633, 'Nevada': 31316007, 'New Hampshire': 98857889, 'New Jersey': 240135510, 'New Mexico': 99743752, 'New York': 2205949608, 'North Carolina': 1154347750, 'North Dakota': 22471682, 'Ohio': 734159508, 'Oklahoma': 90675755, 'Oregon': 274614404, 'Pennsylvania': 1570151520, 'Rhode Island': 150833713, 'South Carolina': 179069761, 'South Dakota': 21563049, 'Tennessee': 512414823, 'Texas': 1097661190, 'Utah': 185147981, 'Vermont': 48758135, 'Virgin Islands': 1383174, 'Virginia': 349479689, 'Washington': 952837210, 'West Virginia': 24040666, 'Wisconsin': 421776499, 'Wyoming': 9477709}\n"
     ]
    }
   ],
   "source": [
    "print(us_states[\"DC\"][\"name\"])\n",
    "fbs = pickle.load(open(dataDir+moneyFile, \"rb\"))\n",
    "print(fbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NV\n",
      "Nevada\n",
      "AZ\n",
      "Arizona\n",
      "WI\n",
      "Wisconsin\n",
      "GA\n",
      "Georgia\n",
      "KS\n",
      "Kansas\n",
      "CT\n",
      "Connecticut\n",
      "IN\n",
      "Indiana\n",
      "ME\n",
      "Maine\n",
      "MA\n",
      "Massachusetts\n",
      "MT\n",
      "Montana\n",
      "MD\n",
      "Maryland\n",
      "AR\n",
      "Arkansas\n",
      "AL\n",
      "Alabama\n",
      "VA\n",
      "Virginia\n",
      "NE\n",
      "Nebraska\n",
      "KY\n",
      "Kentucky\n",
      "NY\n",
      "New York\n",
      "CO\n",
      "Colorado\n",
      "VT\n",
      "Vermont\n",
      "SD\n",
      "South Dakota\n",
      "MI\n",
      "Michigan\n",
      "MO\n",
      "Missouri\n",
      "NC\n",
      "North Carolina\n",
      "RI\n",
      "Rhode Island\n",
      "ID\n",
      "Idaho\n",
      "DE\n",
      "Delaware\n",
      "DC\n",
      "District of Columbia\n",
      "NH\n",
      "New Hampshire\n",
      "MN\n",
      "Minnesota\n",
      "ND\n",
      "North Dakota\n",
      "OK\n",
      "Oklahoma\n",
      "IA\n",
      "Iowa\n",
      "TN\n",
      "Tennessee\n",
      "FL\n",
      "Florida\n",
      "LA\n",
      "Louisiana\n",
      "NM\n",
      "New Mexico\n",
      "WY\n",
      "Wyoming\n",
      "PA\n",
      "Pennsylvania\n",
      "SC\n",
      "South Carolina\n",
      "UT\n",
      "Utah\n",
      "WV\n",
      "West Virginia\n",
      "WA\n",
      "Washington\n",
      "MS\n",
      "Mississippi\n",
      "OR\n",
      "Oregon\n",
      "IL\n",
      "Illinois\n",
      "NJ\n",
      "New Jersey\n",
      "CA\n",
      "California\n",
      "OH\n",
      "Ohio\n",
      "TX\n",
      "Texas\n"
     ]
    }
   ],
   "source": [
    "for code in us_states:\n",
    "    print(code)\n",
    "    print(us_states[code][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bladder\n",
      "Breast\n",
      "Colorectal\n",
      "Liver\n",
      "Lung\n",
      "Pancreatic\n",
      "Prostate\n",
      "Skin\n",
      "Stomach\n",
      "      Bladder  Breast  Colorectal  Liver  Lung  Pancreatic  Prostate  Skin  \\\n",
      "1975      571    1648          75   2157  1779         714       222  1536   \n",
      "1976      565    1610          84   2092  1775         703       233  1562   \n",
      "1977      614    1955          97   2054  1868         740       285  1694   \n",
      "1978      639    1875         170   2122  1950         784       252  1749   \n",
      "1979      692    1929         190   2333  2267         893       323  1920   \n",
      "\n",
      "      Stomach  \n",
      "1975      960  \n",
      "1976      943  \n",
      "1977      969  \n",
      "1978      991  \n",
      "1979     1005  \n"
     ]
    }
   ],
   "source": [
    "##read in cancer data for list of cancers, monthly\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "#df = pd.read_csv(\"FundingPerState.csv\",header=0)\n",
    "#dic = Series(df.FUNDING.values,index=df.LOCATION).to_dict()\n",
    "\n",
    "cancersforout = ['Bladder','Breast','Colorectal','Liver','Lung','Pancreatic','Prostate','Skin','Stomach']\n",
    "#cancersforout = ['Bladder','Breast']\n",
    "years = range(1975,2015)\n",
    "#years = [2016]\n",
    "cPd = pd.DataFrame(columns = cancersforout, index = years)\n",
    "\n",
    "searches = []\n",
    "for c in cancersforout:\n",
    "    tempSearches = []\n",
    "    for y in years:\n",
    "        tempStr = c.lower() + \"+AND+cancer&mindate=\"+str(y)+\"/01/01&maxdate=\"+str(y)+\"/12/31\"\n",
    "        tempSearches.append(tempStr)\n",
    "    searches.append(tempSearches)\n",
    "\n",
    "async def fetch2(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text()\n",
    "    \n",
    "###add states correlating with responses############\n",
    "async def run2(ss):\n",
    "    tasks = []\n",
    "\n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    async with ClientSession() as session:\n",
    "        for s in ss:\n",
    "            tu = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=\"+s+\"&usehistory=y&retmode=json\"\n",
    "            task = asyncio.ensure_future(fetch2(tu, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # you now have all response bodies in this variable\n",
    "        #responses can be converted to json, originally were strings\n",
    "        #print(json.loads(responses[0]))\n",
    "    return responses\n",
    "\n",
    "def getRecordSet(ss):\n",
    "    pubCounts = []\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(run2(ss))\n",
    "    res = loop.run_until_complete(future)\n",
    "    return res\n",
    "    \n",
    "for i, search in enumerate(searches):\n",
    "    searchset = getRecordSet(search)\n",
    "    search_data = []\n",
    "    for s in searchset:\n",
    "        tempdata = json.loads(s)\n",
    "        temprecords = int(tempdata[\"esearchresult\"]['count'])\n",
    "        search_data.append(temprecords)\n",
    "    cPd[cancersforout[i]] = search_data\n",
    "    print(cancersforout[i])\n",
    "\n",
    "print(cPd.head())\n",
    "output = open(\"cancerPublicationsPanda.pkl\", 'wb')\n",
    "pickle.dump(cPd, output)\n",
    "#print(dic)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bladder  Breast  Colorectal  Liver   Lung  Pancreatic  Prostate  Skin  \\\n",
      "1975      571    1648          75   2157   1779         714       222  1536   \n",
      "1976      565    1610          84   2092   1775         703       233  1562   \n",
      "1977      614    1955          97   2054   1868         740       285  1694   \n",
      "1978      639    1875         170   2122   1950         784       252  1749   \n",
      "1979      692    1929         190   2333   2267         893       323  1920   \n",
      "1980      711    2155         211   2424   2358         875       380  1944   \n",
      "1981      765    2136         282   2402   2379         887       420  1950   \n",
      "1982      818    2239         308   2514   2756         925       389  2122   \n",
      "1983      996    2395         375   2991   2956        1000       440  2299   \n",
      "1984     1149    2790         406   3209   3323        1063       515  2467   \n",
      "1985     1169    2871         510   3230   3510        1146       586  2509   \n",
      "1986     1125    2883         636   3340   3479        1169       555  2513   \n",
      "1987     1211    2944         698   3306   3523        1134       713  2425   \n",
      "1988     1223    3261         883   3461   3676        1144       762  2631   \n",
      "1989     1344    3826        1070   3992   4041        1381       775  2844   \n",
      "1990     1377    4014        1106   4105   4312        1444       876  2984   \n",
      "1991     1338    3930        1174   4000   4000        1343       989  2850   \n",
      "1992     1369    4527        1395   3958   4329        1408      1116  2917   \n",
      "1993     1357    4735        1436   4134   4432        1405      1367  2993   \n",
      "1994     1385    5461        1569   4255   4839        1483      1707  3109   \n",
      "1995     1379    5607        1793   4368   4688        1555      1738  3286   \n",
      "1996     1423    6108        1985   4386   4910        1702      2040  3361   \n",
      "1997     1250    5882        1781   3872   4511        1480      2172  3029   \n",
      "1998     1310    6536        2152   4473   4947        1732      2422  3458   \n",
      "1999     1428    7040        2365   4502   5091        1973      2500  3658   \n",
      "2000     1491    7964        2701   4772   5447        1891      2940  3892   \n",
      "2001     1570    8153        2803   5053   5966        2018      3155  3977   \n",
      "2002     1765    9409        3417   5943   6957        2402      3882  4448   \n",
      "2003     1867    9642        3638   6042   6983        2406      4251  4618   \n",
      "2004     1784   10194        3725   6137   7512        2485      4578  4763   \n",
      "2005     1918   11169        4389   6584   8165        2752      4925  5095   \n",
      "2006     2035   11105        4387   6532   7861        2829      5125  5438   \n",
      "2007     2109   12047        4916   7066   8868        3144      5651  5691   \n",
      "2008     2249   12613        5036   7450   9035        3396      5811  5884   \n",
      "2009     2244   13043        5473   7647   9541        3606      5870  6229   \n",
      "2010     2358   14470        5824   7838  10465        3827      6303  6362   \n",
      "2011     2462   15506        6475   8916  11206        4252      6987  6916   \n",
      "2012     2640   16153        7016   9542  12023        4510      7242  7140   \n",
      "2013     3003   17619        7650  10274  13297        4745      7810  7309   \n",
      "2014     3192   19184        8787  11885  15393        5490      8526  7935   \n",
      "\n",
      "      Stomach  \n",
      "1975      960  \n",
      "1976      943  \n",
      "1977      969  \n",
      "1978      991  \n",
      "1979     1005  \n",
      "1980     1030  \n",
      "1981     1062  \n",
      "1982     1147  \n",
      "1983     1256  \n",
      "1984     1470  \n",
      "1985     1464  \n",
      "1986     1534  \n",
      "1987     1467  \n",
      "1988     1416  \n",
      "1989     1724  \n",
      "1990     1721  \n",
      "1991     1625  \n",
      "1992     1641  \n",
      "1993     1638  \n",
      "1994     1768  \n",
      "1995     1825  \n",
      "1996     1784  \n",
      "1997     1733  \n",
      "1998     1943  \n",
      "1999     1997  \n",
      "2000     2022  \n",
      "2001     2210  \n",
      "2002     2633  \n",
      "2003     2616  \n",
      "2004     2631  \n",
      "2005     2942  \n",
      "2006     2913  \n",
      "2007     3037  \n",
      "2008     3027  \n",
      "2009     3138  \n",
      "2010     3291  \n",
      "2011     3660  \n",
      "2012     3975  \n",
      "2013     4112  \n",
      "2014     4791  \n"
     ]
    }
   ],
   "source": [
    "print(cPd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ClientConnectorError",
     "evalue": "[Errno 61] Cannot connect to host localhost:8080 ssl:False [Can not connect to localhost:8080 [Connect call failed ('127.0.0.1', 8080)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36m_create_direct_connection\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhinfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hostname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msslcontext\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                     local_addr=self._local_addr)\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mhas_cert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sslcontext'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname)\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname)\u001b[0m\n\u001b[1;32m    762\u001b[0m                         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"connect %r to %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/asyncio/selector_events.py\u001b[0m in \u001b[0;36msock_connect\u001b[0;34m(self, sock, address)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/asyncio/selector_events.py\u001b[0m in \u001b[0;36m_sock_connect_cb\u001b[0;34m(self, fut, sock, address)\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;31m# Jump to any except clause below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Connect call failed %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBlockingIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connect call failed ('127.0.0.1', 8080)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mClientConnectorError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                 \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_direct_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36m_create_direct_connection\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;34m'Can not connect to %s:%s [%s]'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                 (req.host, req.port, exc.strerror)) from exc\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientConnectorError\u001b[0m: [Errno 61] Can not connect to localhost:8080 [Connect call failed ('127.0.0.1', 8080)]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mClientConnectorError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-291225d83f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event loop stopped before Future completed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-291225d83f79>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# you now have all response bodies in this variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-291225d83f79>\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(url, session)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mawait\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoroutine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__aenter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, data, json, headers, skip_auto_headers, auth, allow_redirects, max_redirects, encoding, compress, chunked, expect100, read_until_eof, proxy, proxy_auth, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mCeilTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         raise ServerTimeoutError(\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;34m'Cannot connect to host {0[0]}:{0[1]} ssl:{0[2]} [{1}]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     .format(key, exc.strerror)) from exc\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquired\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientConnectorError\u001b[0m: [Errno 61] Cannot connect to host localhost:8080 ssl:False [Can not connect to localhost:8080 [Connect call failed ('127.0.0.1', 8080)]]"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.read()\n",
    "\n",
    "async def run(r):\n",
    "    url = \"http://localhost:8080/{}\"\n",
    "    tasks = []\n",
    "\n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    async with ClientSession() as session:\n",
    "        for i in range(r):\n",
    "            task = asyncio.ensure_future(fetch(url.format(i), session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        # you now have all response bodies in this variable\n",
    "        print(responses)\n",
    "\n",
    "def print_responses(result):\n",
    "    print(result)\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(run(4))\n",
    "loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
